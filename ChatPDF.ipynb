{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Developed ChatPDF, an interactive application utilizing LangChain and Google's FLAN-T5 XXL model. Users can upload PDF documents, which are processed and used as a knowledge base. The system leverages PyMuPDF for document loading, HuggingFace embeddings, Recursive Character TextSplitter for text chunking, Chroma for vector storage, and HuggingFaceHub for large language model integration. Users can query the document for summaries, explanations, and more, facilitating advanced document interaction and understanding."
      ],
      "metadata": {
        "id": "woBcZqKc1yZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technologies used: LangChain, Google's FLAN-T5 XXL, PyMuPDF, HuggingFaceHub, Chroma, Gradio."
      ],
      "metadata": {
        "id": "68-nIRSn8nXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Yq0CDn9sZ6rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "nSMvYZWMZ-i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "v9J3jtruh2am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "wPzdNrSJmNYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "WKfjVKxSmjDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "mNTg9NP6txDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured\n",
        "!pip install unstructured[local-inference]"
      ],
      "metadata": {
        "id": "0KlbcXcZt_Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = my_token\n",
        "\n",
        "chain = None\n",
        "\n",
        "# Function to load and process the PDF document\n",
        "def load_doc(pdf_doc):\n",
        "\n",
        "    global chain   # Global variable to hold the chain object\n",
        "\n",
        "    try:\n",
        "\n",
        "        if pdf_doc is None:  # Checks if a file is uploaded\n",
        "            return \"No file uploaded.\"\n",
        "\n",
        "        # Loads the PDF document using PyMuPDFLoader\n",
        "        loader = PyMuPDFLoader(pdf_doc.name)\n",
        "        documents = loader.load()\n",
        "\n",
        "        # Creates the HuggingFaceEmbeddings object\n",
        "        embedding = HuggingFaceEmbeddings()\n",
        "\n",
        "        # Splits the text into chunks for processing\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        text = text_splitter.split_documents(documents)\n",
        "\n",
        "        # Creates a Chroma vector database to store the text chunks' embeddings\n",
        "        db = Chroma.from_documents(text, embedding)\n",
        "\n",
        "        # Initializing the Hugging Face Hub LLM with specific parameters, I'm using Google's FLAN-T5 here\n",
        "        llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\": 1.0, \"max_length\": 256})\n",
        "\n",
        "        # Creating a RetrievalQA chain using the LLM and Chroma retriever\n",
        "        chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
        "\n",
        "        return 'Document has successfully been loaded'\n",
        "    except Exception as e:\n",
        "        return f\"Error loading document: {str(e)}\"\n",
        "\n",
        "\n",
        "# Function to answer a query using the loaded document\n",
        "def answer_query(query):\n",
        "\n",
        "    global chain\n",
        "\n",
        "    try:\n",
        "        # Checks if the document has been loaded\n",
        "        if chain is None:\n",
        "            return \"Document not loaded yet.\"\n",
        "\n",
        "        # Run the query through the chain and return the result\n",
        "        return chain.run(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error processing query: {str(e)}\"\n",
        "\n",
        "# HTML content for the Gradio interface\n",
        "html = \"\"\"\n",
        "<div style=\"text-align:center; max-width: 700px;\">\n",
        "    <h1>ChatPDF</h1>\n",
        "    <p> Upload a PDF File, then click on Load PDF File. <br>\n",
        "    Once the document has been loaded you can begin chatting with the PDF.\n",
        "</div>\"\"\"\n",
        "\n",
        "# CSS styling for the Gradio interface\n",
        "css = \"\"\"container{max-width:700px; margin-left:auto; margin-right:auto,padding:20px}\"\"\"\n",
        "\n",
        "# Creating the Gradio Blocks interface\n",
        "with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as demo:\n",
        "    gr.HTML(html)\n",
        "\n",
        "    with gr.Column():\n",
        "        gr.Markdown('ChatPDF')\n",
        "        pdf_doc = gr.File(label=\"Load a PDF\", file_types=['.pdf'], type='filepath')  # Ensure type is 'file' to get file object\n",
        "\n",
        "        with gr.Row():\n",
        "            load_pdf = gr.Button('Load PDF File')\n",
        "            status = gr.Textbox(label=\"Status\", placeholder='', interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            input_query = gr.Textbox(label=\"Type in your question\")\n",
        "            output_response = gr.Textbox(label=\"Output\")\n",
        "        submit_query = gr.Button(\"Submit\")\n",
        "\n",
        "        # Defining the interactions between components\n",
        "        load_pdf.click(load_doc, inputs=pdf_doc, outputs=status)\n",
        "        submit_query.click(answer_query, inputs=input_query, outputs=output_response)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "sUlMYCNeis5j",
        "outputId": "20826cfd-0b62-4ab2-f188-3ca74e514e7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a3197ac7259dd57245.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a3197ac7259dd57245.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faAlTftejGqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}