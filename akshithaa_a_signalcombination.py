# -*- coding: utf-8 -*-
"""Akshithaa A_SignalCombination.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VUZjgk1jsS6fOvetKLPyjDdGo1PHaCyV

#Task 2
"""

merged_qr_df

merged_qr_df.to_csv("signals.csv", index=False)

df_signal = pd.read_csv('/content/signals.csv')

"""###Signal 1: AVMD (Adjusted Volume-Momentum Divergence)"""

df_signal['AVMD'] = (
    df_signal['Return'].rolling(3).std() /
    df_signal['Volume'].ewm(span=3, adjust=False).mean()
)
df_signal['AVMD'] = (df_signal['AVMD'] - df_signal['AVMD'].mean()) / df_signal['AVMD'].std()

"""###Signal 2: EWIPI (Exchange-Weighted Input Pressure Index)"""

rolling_fx = df_signal['Exchange Rate'].rolling(6).mean()
ewipi_raw = np.log1p(df_signal['PPI'] * df_signal['Gasoline Price (USD/Litre)']) * (
    df_signal['Exchange Rate'] / rolling_fx
)
df_signal['EWIPI'] = -((ewipi_raw - ewipi_raw.mean()) / ewipi_raw.std())

"""###Signal 3: DSES (Demand-Sentiment Elasticity Score)"""

dses_raw = (
    df_signal['Consumer Confidence Index'] * (df_signal['GDP growth rate'] ** 1.5)
) / (
    (df_signal['Bank Rate'] ** 1.2) * (df_signal['Urban Inflation (%)'] ** 0.8)
)
df_signal['DSES'] = (dses_raw - dses_raw.mean()) / dses_raw.std()

# Final Composite Signal
df_signal['CompositeSignal'] = df_signal[['AVMD', 'EWIPI', 'DSES']].mean(axis=1)

# Defining threshold
threshold = 0.5

# Step 2: Generate trading positions
df_signal['Position'] = 0  # neutral default
df_signal.loc[df_signal['CompositeSignal'] > threshold, 'Position'] = 1   # long/buy
df_signal.loc[df_signal['CompositeSignal'] < -threshold, 'Position'] = -1  # short/sell

df_signal

"""#ML Strategy

##Model 1 (Long-term trading)
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error

# ---- Step 1: Prepare Data ---- #
features = ['AVMD', 'EWIPI', 'DSES']
target = 'Return'

# Prepare DataFrame
df_ml = df_signal.dropna(subset=features + [target]).copy()
df_ml['Return'] = df_ml['Return'] / 100.0

# Target = next month's return
df_ml['TargetReturn'] = df_ml['Return'].shift(-1)
df_ml.dropna(subset=['TargetReturn'], inplace=True)

# ---- Step 2: Train Random Forest ---- #
X = df_ml[features]
y = df_ml['TargetReturn']
X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

rf = RandomForestRegressor(n_estimators=100, max_depth=4, random_state=42)
rf.fit(X_train, y_train)

# Predict and smooth
df_ml['PredictedReturn'] = rf.predict(X) / 100.0  # decimal

# Smoothing
df_ml['PredictedReturnSmoothed'] = df_ml['PredictedReturn'].rolling(window=3).mean()

# Volatility filter
df_ml['Volatility'] = df_ml['Return'].rolling(window=3).std()
vol_threshold = df_ml['Volatility'].quantile(0.7)
low_vol_mask = df_ml['Volatility'] < vol_threshold

# Scaled positions (cap extreme predictions)
threshold = 0.0028
scaled_pred = df_ml['PredictedReturnSmoothed'] / threshold
scaled_pred = scaled_pred.clip(-1, 1)

# Only trade during low volatility periods
df_ml['ScaledPosition'] = 0
df_ml.loc[low_vol_mask, 'ScaledPosition'] = scaled_pred[low_vol_mask]

# Strategy returns
df_ml['StrategyReturn'] = df_ml['ScaledPosition'].shift(1) * df_ml['Return']
df_ml['StrategyReturn'] = df_ml['StrategyReturn'].clip(lower=-0.10)  # Stop-loss simulation

# Filter out extreme strategy returns
df_ml = df_ml[df_ml['StrategyReturn'].abs() < 1]

# Cumulative returns
df_ml['Cumulative Strategy Return'] = (1 + df_ml['StrategyReturn']).cumprod()
df_ml['Cumulative Buy & Hold'] = (1 + df_ml['Return']).cumprod()

# Sharpe Ratio
sharpe = (df_ml['StrategyReturn'].mean() / df_ml['StrategyReturn'].std()) * np.sqrt(12)

# Max Drawdown
rolling_max = df_ml['Cumulative Strategy Return'].cummax()
drawdown = df_ml['Cumulative Strategy Return'] / rolling_max - 1
max_drawdown = drawdown.min()

# Turnover
df_ml['Turnover'] = df_ml['ScaledPosition'].diff().abs()
monthly_turnover = df_ml['Turnover'].mean()
estimated_daily_turnover = monthly_turnover / 22

# ---- Annualized Return ---- #
n_months = len(df_ml)
final_cum_return = df_ml['Cumulative Strategy Return'].iloc[-1]
annualized_return = final_cum_return**(12 / n_months) - 1

# ---- Final Results ---- #
print("\nML Strategy Backtest:")
print(f"Sharpe Ratio: {sharpe:.2f}")
print(f"Max Drawdown: {max_drawdown:.2%}")
print(f"Annualized Return: {annualized_return:.2%}")
print(f"Monthly Turnover: {monthly_turnover:.2%}")
print(f"Estimated Daily Turnover: {estimated_daily_turnover:.2%}")

"""##Model 2(Short-term Trading)"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split
import numpy as np

# Make sure signals and return exist
features = ['AVMD', 'EWIPI', 'DSES']
target = 'Return'

# Drop NA and shift return to predict next month's return
df_ml = df_signal.dropna(subset=features + [target]).copy()
df_ml['TargetReturn'] = df_ml[target].shift(-1)  # Next month's return

# Drop last row (NaN target after shift)
df_ml.dropna(subset=['TargetReturn'], inplace=True)

# Fix this before any backtesting
df_ml['Return'] = df_ml['Return'] / 100.0

# Split into train-test
X = df_ml[features]
y = df_ml['TargetReturn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

rf = RandomForestRegressor(n_estimators=100, max_depth=2, random_state=42)
rf.fit(X_train, y_train)

# Predict next-month return
df_ml['PredictedReturn'] = rf.predict(X)

df_ml['PredictedReturn'] = df_ml['PredictedReturn'] / 100.0

import numpy as np

best_sharpe = -np.inf
best_threshold = None
best_stats = {}

threshold_range = np.linspace(0.001, 0.05, 50)  # try thresholds from 0.1% to 5%

for threshold in threshold_range:
    df_temp = df_ml.copy()

    # Apply thresholding logic
    df_temp['Position'] = 0
    df_temp.loc[df_temp['PredictedReturn'] > threshold, 'Position'] = 1
    df_temp.loc[df_temp['PredictedReturn'] < -threshold, 'Position'] = -1

    # Calculate shifted strategy return
    df_temp['StrategyReturn'] = df_temp['Position'].shift(1) * df_temp['Return']
    df_temp['Turnover'] = df_temp['Position'].diff().abs()

    # Cumulative returns for drawdown and annualized return
    df_temp['CumulativeReturn'] = (1 + df_temp['StrategyReturn']).cumprod()
    rolling_max = df_temp['CumulativeReturn'].cummax()
    drawdown = df_temp['CumulativeReturn'] / rolling_max - 1
    max_drawdown = drawdown.min()

    # Risk metrics
    mean_ret = df_temp['StrategyReturn'].mean()
    std_ret = df_temp['StrategyReturn'].std()
    sharpe = mean_ret / std_ret * np.sqrt(12) if std_ret > 0 else 0
    turnover = df_temp['Turnover'].mean()
    estimated_daily_turnover = turnover / 21

    total_periods = df_temp.shape[0]
    annualized_return = (df_temp['CumulativeReturn'].iloc[-1]) ** (12 / total_periods) - 1 if total_periods > 0 else 0

    # Save if turnover is valid and Sharpe is better
    if turnover < 0.40 and sharpe > best_sharpe:
        best_sharpe = sharpe
        best_threshold = threshold
        best_stats = {
            'Sharpe': sharpe,
            'Turnover': turnover,
            'Threshold': threshold,
            'MaxDrawdown': max_drawdown,
            'AnnualizedReturn': annualized_return,
            'EstimatedDailyTurnover': estimated_daily_turnover
        }

# Print the best result
print("Optimal Threshold Found:")
print(f"Threshold: {best_threshold:.4f}")
print(f"Sharpe Ratio: {best_stats['Sharpe']:.2f}")
print(f"Avg Monthly Turnover: {best_stats['Turnover']:.2%}")
print(f"Estimated Daily Turnover: {best_stats['EstimatedDailyTurnover']:.2%}")
print(f"Max Drawdown: {best_stats['MaxDrawdown']:.2%}")
print(f"Annualized Return: {best_stats['AnnualizedReturn']:.2%}")

